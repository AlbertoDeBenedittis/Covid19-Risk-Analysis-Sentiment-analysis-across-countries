---
title: "Tweeter_Analysis"
author: "Alberto De Benedittis"
date: "11/7/2021"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```

```{r}
library(twitteR)
library(purrr)
library(dplyr)
library(plyr)
library(stringr)
library(ROAuth)
library(RCurl)
library(openssl)
library(httpuv)
library(RColorBrewer) 
library(wordcloud)
library(tm)
library(SnowballC)
library(wordcloud)
library(sentimentr)
library(ggplot2)
library(syuzhet)
library(widyr)
```
The aim of the following analysis is to collect tweets related to COVID from different countries and compare the results. More specifically, we want to output a cloud of word in order to see the most recurrent words/topics associated to COVID in different countries. Moreover will be conducted a sentiment analysis on these collections of tweets in order to understand the feelings associated to COVID. 

__ACCESS TO TWITTER__
```{r}
consumerKey <-  
consumerSecret <-  
accessToken <-  
accessTokenSecret <-  
setup_twitter_oauth(consumerKey,consumerSecret,accessToken,accessTokenSecret)
```
# ITALY 

__COLLECTING THE TWEETS__
```{r}

tweets<-searchTwitter("coronavirus", n=3000, lan="it", since="2021-07-01")

tweets.df<-ldply(tweets, function(t) t$toDataFrame())
```
__SAVING THE TWEETS INTO A CSV__
```{r}
write.csv(tweets.df, "covid_tweets.csv")
```
__CLEANING THE TWEETS__
```{r}
unclean_tweet=sapply(tweets, function(x) x$getText())

clean_tweet = gsub("&amp", "", unclean_tweet)
clean_tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", clean_tweet)
clean_tweet = gsub("@\\w+", "", clean_tweet)
clean_tweet = gsub("[[:punct:]]", "", clean_tweet)
clean_tweet = gsub("[[:digit:]]", "", clean_tweet)
clean_tweet = gsub("http\\w+", "", clean_tweet)
clean_tweet = gsub("[ \t]{2,}", "", clean_tweet)
clean_tweet = gsub("^\\s+|\\s+$", "", clean_tweet)
```


```{r}
# Take out retweet header, there is only one
clean_tweet <- str_replace(clean_tweet,"RT @[a-z,A-Z]*: ","")
# Get rid of hashtags
clean_tweet <- str_replace_all(clean_tweet,"#[a-z,A-Z]*","")
# Get rid of references to other screennames
clean_tweet <- str_replace_all(clean_tweet,"@[a-z,A-Z]*","")  
```

```{r}
stopword <- stopwords('it')
clean_tweet <-  clean_tweet
for (i in 1: length(clean_tweet)){
  removeWords(clean_tweet[i], stopword)
}
```

__WORD CLOUD__
```{r}
wordcloud(clean_tweet, min.freq=5, max.words=200, random.color=TRUE, random.order =FALSE, color=brewer.pal(8,"Dark2"))
```


__CREATING SENTIMENT HISTOGRAM__
```{r}
clean_tweet <- iconv(clean_tweet, from="UTF-8", to="ASCII", sub="")

ew_sentiment <-get_nrc_sentiment((clean_tweet))

sentimentscores <- data.frame(colSums(ew_sentiment[,]))

names(sentimentscores) <- "Score"

sentimentscores <- cbind("sentiment"=rownames(sentimentscores), sentimentscores)

rownames(sentimentscores) <- NULL
```


```{r}
ggplot(sentimentscores, aes(x=sentiment, y=Score))+
  geom_bar(aes(fill=sentiment),
           stat = "identity")+
  ggtitle("Total sentiment based on scores for COVID-19 in Italy")
```


# GERMANY
__COLLECTING THE TWEETS__
```{r}

tweets<-searchTwitter("coronavirus", n=3000, lan="de", since="2021-07-01")

tweets.df<-ldply(tweets, function(t) t$toDataFrame())
```
__SAVING THE TWEETS INTO A CSV__
```{r}
write.csv(tweets.df, "covid_tweets.csv")
```
__CLEANING THE TWEETS__
```{r}
unclean_tweet=sapply(tweets, function(x) x$getText())

clean_tweet = gsub("&amp", "", unclean_tweet)
clean_tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", clean_tweet)
clean_tweet = gsub("@\\w+", "", clean_tweet)
clean_tweet = gsub("[[:punct:]]", "", clean_tweet)
clean_tweet = gsub("[[:digit:]]", "", clean_tweet)
clean_tweet = gsub("http\\w+", "", clean_tweet)
clean_tweet = gsub("[ \t]{2,}", "", clean_tweet)
clean_tweet = gsub("^\\s+|\\s+$", "", clean_tweet)
```


```{r}
# Take out retweet header, there is only one
clean_tweet <- str_replace(clean_tweet,"RT @[a-z,A-Z]*: ","")
# Get rid of hashtags
clean_tweet <- str_replace_all(clean_tweet,"#[a-z,A-Z]*","")
# Get rid of references to other screennames
clean_tweet <- str_replace_all(clean_tweet,"@[a-z,A-Z]*","")  
```

```{r}
stopword <- stopwords('de')
clean_tweet <-  clean_tweet
for (i in 1: length(clean_tweet)){
  removeWords(clean_tweet[i], stopword)
}
```

__WORD CLOUD__
```{r}
wordcloud(clean_tweet, min.freq=5, max.words=200, random.color=TRUE, random.order =FALSE, color=brewer.pal(8,"Dark2"))
```

__CREATING SENTIMENT HISTOGRAM__
```{r}
clean_tweet <- iconv(clean_tweet, from="UTF-8", to="ASCII", sub="")

ew_sentiment <-get_nrc_sentiment((clean_tweet))

sentimentscores <- data.frame(colSums(ew_sentiment[,]))

names(sentimentscores) <- "Score"

sentimentscores <- cbind("sentiment"=rownames(sentimentscores), sentimentscores)

rownames(sentimentscores) <- NULL
```


```{r}
ggplot(sentimentscores, aes(x=sentiment, y=Score))+
  geom_bar(aes(fill=sentiment),
           stat = "identity")+
  ggtitle("Total sentiment based on scores for COVID-19 in Germany")
```

# SPAIN 
__COLLECTING THE TWEETS__
```{r}

tweets<-searchTwitter("coronavirus", n=3000, lan="es", since="2021-07-01")

tweets.df<-ldply(tweets, function(t) t$toDataFrame())
```
__SAVING THE TWEETS INTO A CSV__
```{r}
write.csv(tweets.df, "covid_tweets.csv")
```
__CLEANING THE TWEETS__
```{r}
unclean_tweet=sapply(tweets, function(x) x$getText())

clean_tweet = gsub("&amp", "", unclean_tweet)
clean_tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", clean_tweet)
clean_tweet = gsub("@\\w+", "", clean_tweet)
clean_tweet = gsub("[[:punct:]]", "", clean_tweet)
clean_tweet = gsub("[[:digit:]]", "", clean_tweet)
clean_tweet = gsub("http\\w+", "", clean_tweet)
clean_tweet = gsub("[ \t]{2,}", "", clean_tweet)
clean_tweet = gsub("^\\s+|\\s+$", "", clean_tweet)
```


```{r}

# Take out retweet header, there is only one
clean_tweet <- str_replace(clean_tweet,"RT @[a-z,A-Z]*: ","")
# Get rid of hashtags
clean_tweet <- str_replace_all(clean_tweet,"#[a-z,A-Z]*","")
# Get rid of references to other screennames
clean_tweet <- str_replace_all(clean_tweet,"@[a-z,A-Z]*","")  
```

```{r}
stopword <- stopwords('es')
clean_tweet <-  clean_tweet
for (i in 1: length(clean_tweet)){
  removeWords(clean_tweet[i], stopword)
}
```

__WORD CLOUD__
```{r}
wordcloud(clean_tweet, min.freq=5, max.words=200, random.color=TRUE, random.order =FALSE, color=brewer.pal(8,"Dark2"))
```

__CREATING SENTIMENT HISTOGRAM__
```{r}
clean_tweet <- iconv(clean_tweet, from="UTF-8", to="ASCII", sub="")

ew_sentiment <-get_nrc_sentiment((clean_tweet))

sentimentscores <- data.frame(colSums(ew_sentiment[,]))

names(sentimentscores) <- "Score"

sentimentscores <- cbind("sentiment"=rownames(sentimentscores), sentimentscores)

rownames(sentimentscores) <- NULL
```


```{r}
ggplot(sentimentscores, aes(x=sentiment, y=Score))+
  geom_bar(aes(fill=sentiment),
           stat = "identity")+
  ggtitle("Total sentiment based on scores for COVID-19 in Spain")
```


# SWEDEN 
__COLLECTING THE TWEETS__
```{r}

tweets<-searchTwitter("covid", n=3000, lan="sv", since="2021-05-01")

tweets.df<-ldply(tweets, function(t) t$toDataFrame())
```
__SAVING THE TWEETS INTO A CSV__
```{r}
write.csv(tweets.df, "covid_tweets.csv")
```
__CLEANING THE TWEETS__
```{r}
unclean_tweet=sapply(tweets, function(x) x$getText())

clean_tweet = gsub("&amp", "", unclean_tweet)
clean_tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", clean_tweet)
clean_tweet = gsub("@\\w+", "", clean_tweet)
clean_tweet = gsub("[[:punct:]]", "", clean_tweet)
clean_tweet = gsub("[[:digit:]]", "", clean_tweet)
clean_tweet = gsub("http\\w+", "", clean_tweet)
clean_tweet = gsub("[ \t]{2,}", "", clean_tweet)
clean_tweet = gsub("^\\s+|\\s+$", "", clean_tweet)
```


```{r}
# Take out retweet header, there is only one
clean_tweet <- str_replace(clean_tweet,"RT @[a-z,A-Z]*: ","")
# Get rid of hashtags
clean_tweet <- str_replace_all(clean_tweet,"#[a-z,A-Z]*","")
# Get rid of references to other screennames
clean_tweet <- str_replace_all(clean_tweet,"@[a-z,A-Z]*","")  
```

```{r}
stopword <- stopwords('sv')
clean_tweet <-  clean_tweet
for (i in 1: length(clean_tweet)){
  removeWords(clean_tweet[i], stopword)
}
```

__WORD CLOUD__
```{r}
wordcloud(clean_tweet, min.freq=5, max.words=200, random.color=TRUE, random.order =FALSE, color=brewer.pal(8,"Dark2"))
```

__CREATING SENTIMENT HISTOGRAM__
```{r}
clean_tweet <- iconv(clean_tweet, from="UTF-8", to="ASCII", sub="")

ew_sentiment <-get_nrc_sentiment((clean_tweet))

sentimentscores <- data.frame(colSums(ew_sentiment[,]))

names(sentimentscores) <- "Score"

sentimentscores <- cbind("sentiment"=rownames(sentimentscores), sentimentscores)

rownames(sentimentscores) <- NULL
```


```{r}
ggplot(sentimentscores, aes(x=sentiment, y=Score))+
  geom_bar(aes(fill=sentiment),
           stat = "identity")+
  ggtitle("Total sentiment based on scores for COVID-19 in Sweden")
```
# UNITED KINGDOM 
__COLLECTING THE TWEETS__
```{r}

tweets<-searchTwitter("coronavirus", n=3000, lan="en", since="2021-07-01",  geocode='53.383331,-1.466667,258mi' )

tweets.df<-ldply(tweets, function(t) t$toDataFrame())
```
__SAVING THE TWEETS INTO A CSV__
```{r}
write.csv(tweets.df, "covid_tweets.csv")
```
__CLEANING THE TWEETS__
```{r}
unclean_tweet=sapply(tweets, function(x) x$getText())

clean_tweet = gsub("&amp", "", unclean_tweet)
clean_tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", clean_tweet)
clean_tweet = gsub("@\\w+", "", clean_tweet)
clean_tweet = gsub("[[:punct:]]", "", clean_tweet)
clean_tweet = gsub("[[:digit:]]", "", clean_tweet)
clean_tweet = gsub("http\\w+", "", clean_tweet)
clean_tweet = gsub("[ \t]{2,}", "", clean_tweet)
clean_tweet = gsub("^\\s+|\\s+$", "", clean_tweet)
```


```{r}
# Take out retweet header, there is only one
clean_tweet <- str_replace(clean_tweet,"RT @[a-z,A-Z]*: ","")
# Get rid of hashtags
clean_tweet <- str_replace_all(clean_tweet,"#[a-z,A-Z]*","")
# Get rid of references to other screennames
clean_tweet <- str_replace_all(clean_tweet,"@[a-z,A-Z]*","")  
```

```{r}
stopword <- stopwords('en')
clean_tweet <-  clean_tweet
for (i in 1: length(clean_tweet)){
  removeWords(clean_tweet[i], stopword)
}
```

__WORD CLOUD__
```{r}
wordcloud(clean_tweet, min.freq=5, max.words=200, random.color=TRUE, random.order =FALSE, color=brewer.pal(8,"Dark2"))
```

__CREATING SENTIMENT HISTOGRAM__
```{r}
clean_tweet <- iconv(clean_tweet, from="UTF-8", to="ASCII", sub="")

ew_sentiment <-get_nrc_sentiment((clean_tweet))

sentimentscores <- data.frame(colSums(ew_sentiment[,]))

names(sentimentscores) <- "Score"

sentimentscores <- cbind("sentiment"=rownames(sentimentscores), sentimentscores)

rownames(sentimentscores) <- NULL
```


```{r}
ggplot(sentimentscores, aes(x=sentiment, y=Score))+
  geom_bar(aes(fill=sentiment),
           stat = "identity")+
  ggtitle("Total sentiment based on scores for COVID-19 in Spain")
```
# UNITED STATES 
__COLLECTING THE TWEETS__
```{r}

tweets<-searchTwitter("coronavirus", n=3000, lan="en", since="2021-05-01", 
geocode='39.099724,-94.578331,1000mi')

tweets.df<-ldply(tweets, function(t) t$toDataFrame())
```
__SAVING THE TWEETS INTO A CSV__
```{r}
write.csv(tweets.df, "covid_tweets.csv")
```
__CLEANING THE TWEETS__
```{r}
unclean_tweet=sapply(tweets, function(x) x$getText())

clean_tweet = gsub("&amp", "", unclean_tweet)
clean_tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", clean_tweet)
clean_tweet = gsub("@\\w+", "", clean_tweet)
clean_tweet = gsub("[[:punct:]]", "", clean_tweet)
clean_tweet = gsub("[[:digit:]]", "", clean_tweet)
clean_tweet = gsub("http\\w+", "", clean_tweet)
clean_tweet = gsub("[ \t]{2,}", "", clean_tweet)
clean_tweet = gsub("^\\s+|\\s+$", "", clean_tweet)
```


```{r}
# Take out retweet header, there is only one
clean_tweet <- str_replace(clean_tweet,"RT @[a-z,A-Z]*: ","")
# Get rid of hashtags
clean_tweet <- str_replace_all(clean_tweet,"#[a-z,A-Z]*","")
# Get rid of references to other screennames
clean_tweet <- str_replace_all(clean_tweet,"@[a-z,A-Z]*","")  
```

```{r}
stopword <- stopwords('en')
clean_tweet <-  clean_tweet
for (i in 1: length(clean_tweet)){
  removeWords(clean_tweet[i], stopword)
}
```

__WORD CLOUD__
```{r}
wordcloud(clean_tweet, min.freq=5, max.words=200, random.color=TRUE, random.order =FALSE, color=brewer.pal(8,"Dark2"))
```

__CREATING SENTIMENT HISTOGRAM__
```{r}
clean_tweet <- iconv(clean_tweet, from="UTF-8", to="ASCII", sub="")

ew_sentiment <-get_nrc_sentiment((clean_tweet))

sentimentscores <- data.frame(colSums(ew_sentiment[,]))

names(sentimentscores) <- "Score"

sentimentscores <- cbind("sentiment"=rownames(sentimentscores), sentimentscores)

rownames(sentimentscores) <- NULL
```


```{r}
ggplot(sentimentscores, aes(x=sentiment, y=Score))+
  geom_bar(aes(fill=sentiment),
           stat = "identity")+
  ggtitle("Total sentiment based on scores for COVID-19 in the United States")
```


